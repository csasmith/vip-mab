# vip-mab
Research on the multi-armed bandit problem and its variants <br><br>


### Classic K-Armed Bandit Papers and Resources

[Finite-time Analysis of the Multiarmed Bandit Problem [Auer, Cesa-Bianchi, Fischer]](https://people.eecs.berkeley.edu/~russell/classes/cs294/s11/readings/Auer+al:2002.pdf) | [Alt](https://link.springer.com/article/10.1023/A:1013689704352)

[Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems [Bubeck, Cesa-Bianchi]](https://arxiv.org/abs/1204.5721)

[Introduction to Multi-Armed Bandits [Slivkins]](https://arxiv.org/abs/1904.07272)

[Bandit Algorithms [Lattimore, Szepesvari]](https://tor-lattimore.com/downloads/book/book.pdf)

[Exploration-exploitation trade-off using variance estimates in multi-armed bandits [Audibert, Munos, Szepesvari]](http://certis.enpc.fr/~audibert/Mes%20articles/TCS08.pdf)

[Using confidence bounds for exploitation-exploration trade-offs [Auer]](https://dl.acm.org/doi/10.5555/944919.944941) | [Alt](https://www.jmlr.org/papers/volume3/auer02a/auer02a.pdf)
<br><br>

### Contextual Bandit Resources

[Associative Reinforcement Learning using Linear Probabilistic Concepts [Abe, Long]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.31.3738&rep=rep1&type=pdf) | [Alt](http://phillong.info/publications/peval.pdf)

[Using confidence bounds for exploitation-exploration trade-offs [Auer]](https://dl.acm.org/doi/10.5555/944919.944941) | [Alt](https://www.jmlr.org/papers/volume3/auer02a/auer02a.pdf)

[Contextual Bandits with Linear Payoff Functions [Chu, Li, Reyzin, Schapire]](http://proceedings.mlr.press/v15/chu11a.html) | [Alt](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/camera-ready-4.pdf)

[Stochastic Linear Optimization under Bandit Feedback [Dani, Hayes, Kakade]](https://homes.cs.washington.edu/~sham/papers/ml/bandit_linear_long.pdf) | [Alt](https://www.semanticscholar.org/paper/Stochastic-Linear-Optimization-under-Bandit-Dani-Hayes/551e19e5113cdff60a3c545d684fc4b9eb9a7306)

[Differentially-Private Federated Linear Bandits [Dubey, Pentland]](https://arxiv.org/abs/2010.11425)

[Improved Algorithms for Linear Stochastic Bandits [Yadkori, Pal, Szepesvari]](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.636.6894&rep=rep1&type=pdf) | [Alt](https://papers.nips.cc/paper/2011/hash/e1d5be1c7f2f456670de3d53c7b54f4a-Abstract.html)

[Forced-Exploration Based Algorithms for Playing in Stochastic Linear Bandits [Yadkori, Antos, Szepesvari]](https://yasin-abbasi.github.io/LinearBandit.pdf) | [Alt](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.704.7754)

[Forced-Exploration Based Algorithms for Playing in Bandits with Large Action Sets [Yadkori]](https://yasin-abbasi.github.io/Yasin-MSc-Thesis.pdf) 
<br><br>

### Nonstationary Bandit Resources

[Restless Bandits: Activity Allocation in a Changing World [Whittle]](https://www.jstor.org/stable/pdf/3214163.pdf?refreqid=excelsior%3Abfbb51ca2a6c95c7bf708fc7f33f31eb)

[Stochastic Multi-Armed-Bandit Problem with Non-stationary Rewards [Besbes, Gur, Zeevi]](https://papers.nips.cc/paper/2014/file/903ce9225fca3e988c2af215d4e544d3-Paper.pdf)

[Efficient Contextual Bandits in Non-stationary Worlds [Luo, Wei, Agarwal, Langford]](https://arxiv.org/abs/1708.01799)

[On Abruptly-Changing and Slowly-Varying Multiarmed Bandit Problems [Wei, Srivastava]](https://arxiv.org/abs/1802.08380)

[On Upper-Confidence Bound Policies for Non-Stationary Bandit Problems [Garivier, Moulines]](https://arxiv.org/abs/0805.3415)

[Multi-armed Bandit, Dynamic Environments and Meta-Bandits [Hartland, Gelly, Baskiotis, Teytaud, Sebag]](https://hal.archives-ouvertes.fr/hal-00113668/document)

[Using confidence bounds for exploitation-exploration trade-offs [Auer]](https://dl.acm.org/doi/10.5555/944919.944941) | [Alt](https://www.jmlr.org/papers/volume3/auer02a/auer02a.pdf)

[Regret Bounds for Restless Markov Bandits [Ortner, Ryabko, Auer, Munos]](https://arxiv.org/abs/1209.2693)

[The non-stochastic multi-armed bandit problem [Auer, Cesa-Bianchi, Freund, Schapire]](https://cseweb.ucsd.edu/~yfreund/papers/bandits.pdf)
<br> <br>

### Distributed Bandit Resources

[Federated Bandit: A Gossiping Approach [Zhu, Zhu, Liu, Liu]](https://arxiv.org/abs/2010.12763)

[Differentially-Private Federated Linear Bandits [Dubey, Pentland]](https://arxiv.org/abs/2010.11425)

[On Distributed Cooperative Decision-Making in Multiarmed Bandits [Landgren, Srivastava, Leonard]](https://arxiv.org/abs/1512.06888)

[Distributed Cooperative Decision-Making in Multiarmed Bandits: Frequentist and Bayesian Algorithms [Landgren, Srivastava, Leonard]](https://arxiv.org/abs/1606.00911) 

[Individual Regret in Cooperative Nonstochastic Multi-Armed Bandits [Bar-On, Mansour]](https://arxiv.org/abs/1907.03346)

[Delay and Cooperation in Nonstochastic Bandits [Cesa-Bianchi, Gentile, Mansour, Minora]](https://arxiv.org/abs/1602.04741)
<br><br>

### Differential Privacy Resources

[Federated Bandit: A Gossiping Approach [Zhu, Zhu, Liu, Liu]](https://arxiv.org/abs/2010.12763)

[Differentially-Private Federated Linear Bandits [Dubey, Pentland]](https://arxiv.org/abs/2010.11425)

[The Algorithmic Foundations of Differential Privacy [Dwork, Roth]](https://columbia.github.io/private-systems-class/papers/Dwork2013Foundations.pdf) | [Alt](https://dl.acm.org/doi/10.1561/0400000042)

[Data Cooperatives: Towards a Foundation for Decentralized Personal Data Management [Hardjono, Pentland]](https://arxiv.org/abs/1905.08819)
- Not strictly about differential privacy, but provides great motivation/applications for DP algorithms
<br><br>

### On Bandit Applications and Implementations

[A Survey on Practical Applications of Multi-Armed and Contextual Bandits [Bouneffouf, Rish]](https://arxiv.org/pdf/1904.10040.pdf)

[Large-scale Open Dataset, Pipeline, and Benchmark for Bandit Algorithms [Saito, Aihara, Matsutani, Narita]](https://arxiv.org/abs/2008.07146)

[SMPyBandits research framework python package](https://smpybandits.github.io/)


